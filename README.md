# Music Genre Research Project (MGRP)

## About this Project

We are researchers in the Lin Lab at FCU.
We love to study music genre classification.

## Setup
- Use pyenv to install python 3.13.0
```bash
pyenv shell 3.13.0
python -m venv env
source env/bin/activate
```
- Install dependencies
```bash
pip install -r requirements.txt
```

## Project requirements
- Music files shoudl be trimmed to the middle 30-seconds.
- Versions of Python, PyTorch, NVIDIA drivers, and CUDA Toolkit that play well together
Our setup uses:
```
- Python 3.13.0
- PyTorch: 2.8.0+cu128 (compiled with CUDA 12.8)
- NVIDIA Driver Version: 535.247.01
- CUDA Toolkit: 13.0
```

## What can you do with this project?

### You can process music data
- GTZAN
```
python src/data/MFCC_GTZAN_extract.py gtzan-data/processed-songs gtzan-data/splits gtzan-data/mfccs_splits
```

- FMA
```
python src/data/MFCC_FMA_extract.py fma-data/fma_medium src/data/fma_mp3_genres.json fma-data/splits fma-data/mfccs_splits
```


## You can train a variety of models with our default settings in `src/core/constants.py`

- Fully Connected (FC) Model
```
python src/training/train_model.py --data gtzan-data/mfccs_splits --model FC --output outputs/gtzan-fc
```

- Available types: ['FC', 'CNN', 'LSTM', 'GRU', 'xLSTM', 'Transformer', 'VGG16', 'ViT']



## You can customize single training runs using in-line arguments

- Override specific hyperparameters (other parameters use defaults from constants.py)

```
python src/training/train_model.py --data gtzan-data/mfccs_splits --model FC --output outputs/gtzan-fc --epochs 50 --batch-size 32 --lr 0.001

# Common customization options:
# --epochs <int>           Maximum number of training epochs
# --batch-size <int>       Batch size for training
# --lr <float>             Learning rate
# --dropout <float>        Dropout probability (0-1)
# --hidden-size <int>      Hidden layer size
# --num-layers <int>       Number of layers
# --patience <int>         Early stopping patience
# --verbose                Enable verbose logging
```

## You can study the results of your training process with our evaluation and analysis tools
- Check Tensorboard for visualizing gradients, etc.
- Check autogenerated Accuracy and Loss plots
- Check evaluation stage confuson matrix and statistics
- Analyze a set of training runs with our `src/analysis` tools 
```
python src/analysis/run_analysis.py --input-dir ./my-outputs --output-dir ./my-analysis
```

## You can test the features of this project
### Run all tests with: `python test.py`
- Use the `--fix` tag to auto-correct linting errors.
- Use the `--training` tag to run with with the (slower) training routine tests.

## You can contribute to this project!
### How about making a Pull Request (PR) and contributing your own feature?
### How about helping us find and fix some bugs?

## Contributors:
Lab Leader: @peichunpclin
Developer/Maintainer: @ericodle

## TODO
### generate test set for FMA and add FMA preprocessing test
### Add analysis tests
### Make new feature: src/hyperparameter_search
### Make new feature: src/fuzzy_logic
### Make new feature: src/multimodal_features
### Make new feature: src/GAN_augmentation
### Make new feature: src/NAS (neural architecture search)